= Compact Serialization Binary Specification
:description: This document describes the binary specification of compact serialization. You will learn what serialized data look like in binary.

{description}

== Introduction

Every serialized user object consists of a header and data. There is also a schema that is separate from the serialized object. Schemas and serialized user objects are linked using the schema id written in the data section.

== Data Types

The table below shows the data types that are supported by compact serialization.

Endianness for primitives is configurable and by default, they are written in BIG_ENDIAN. This configuration is applied to user types and also all the primitives used in the format. These include the size of the arrays, number of items, length of the data, schema-id, offsets, etc. The endianness is inherited from the existing endianness configuration, a new endianness config isn't introduced for compact.

[cols="1,1,1,1,1,1,1,1,3,1"]
|===
|Type |Java |C++ |C# |Python |Node.js |Go |SQL |Description| Fixed Size
|boolean |boolean |bool |bool |bool |boolean |bool |BOOLEAN |true or false represented by 1 bit as either 1 or 0. Up to 8 booleans packed into a single byte |yes
|int8
|byte
|int8_t
|sbyte
|int
|number
|int8
|TINYINT
|8 bit two's complement signed integer
|yes
|int16
|short
|int16_t
|short
|int
|number
|int16
|SMALLINT
|16-bit two's-complement signed integer
|yes
|int32
|int
|int32_t
|int
|int
|number
|int32
|INTEGER
|32-bit two's-complement signed integer
|yes
|int64
|long
|int64_t
|long
|int
|Long
|int64
|BIGINT
|64-bit two's-complement signed integer
|yes
|float32
|float
|float
|float
|float
|number
|float32
|REAL
|32-bit IEEE 754 floating-point number
|yes
|float64
|double
|double
|double
|float
|number
|float64
|DOUBLE
|64-bit IEEE 754 floating-point number
|yes
|string
|String
|optional<std::string>
|string?
|typing.Optional[str]
|string \| null
|*string
|STRING
|null or number of bytes in the string(iint32) + UTF-8 string https://tools.ietf.org/html/rfc3629
|no
|decimal
|BigDecimal
|optional<hazelcast:client:decimal>
|HBigDecimal?
|typing.Optional[decimal.Decimal]
|BigDecimal \| null
|*types.Decimal
|DECIMAL
|null or 
Arbitrary precision and scale floating-point number: represented as unscaledValue x 10 ^ -scale 
unscaledValue: Array of int8 (byte array containing the two's-complement binary representation in big-endian byte-order: the most significant byte is in the zeroth element.)
scale : single int32 for scale
|no
|time
|LocalTime
|optional<hazelcast:client:local_time
|HLocalTime?
|typing.Optional[datetime.time]
|LocalTime \| null
|*types.LocalTime
|TIME
|null or
HH-MI-SS-NN
int8: hour 
int8: minute
int8: seconds
int32: nanoseconds
|no(since it is nullable)
|date
|LocalDate
|optional<hazelcast:client:local_date>
|HLocalDate?
|typing.Optional[datetime.date]
|LocalDate \| null
|*types.LocalDate
|DATE
|null or
YYYY-MM-DD from -999999999-01-1 to 999999999-12-31
int32: year
 int8: month 
int8: dayOfMonth
|no(since it is nullable)
|timestamp
|LocalDateTime
|optional<hazelcast:client:local_date_time>
|HLocalDateTime?
|typing.Optional[datetime.datetime]
|LocalDateTime \| null
|*types.LocalDateTime
|TIMESTAMP
|null or
YYYY-MM-DD-HH-MI-SS-NN
int32: year
int8: month
int8: dayOfMonth
int8 : hour
int8: minute
int8: seconds
iint32: nanoseconds
|no(since it is nullable)
|timestampWithTimeZone
|OffsetDateTime
|optional<hazelcast:client:offset_date_time>
|HOffsetDateTime?
|typing.Optional[datetime.datetime]
|OffsetDateTime \| null
|*types.OffsetDateTime
|TIMESTAMP W/ TZ
|null or
YYYY-MM-DD-HH-MI-SS-MM Zone
int32: year
int8: month
int8:dayOfMonth
int8 : hour
int8: minute
int8: seconds
int32: nanoseconds
int32 : offsetSeconds. 
offsetSeconds is range between +/-18:00:00 hour
|no(since it is nullable)
|compact
|T
|template<typename T> optional<T>
|T?
|typing.Optional[typing.Any]
|T \| null
|interface{}
|OBJECT
|A user defined compact
|no
|boolean[]
|boolean[]
|optional<std::vector<bool>>
|bool[]?
|typing.Optional[typing.List[bool]]
|boolean[] \| null
|[]bool
|
|Array of booleans
|no
|int8[]
|byte[]
|boost::optional<std::vector<int8_t>>
|sbyte[]?
|typing.Optional[typing.List[int]]
|Buffer \| null
|[]int8
|
|Array of int8s
|no
|int16[]
|short[]
|optional<std::vector<int16_t>>
|short[]?
|typing.Optional[typing.List[int]]
|number[] \| null
|[]int16
|
|Array of int16s
|no
|int32[]
|int[]
|optional<std::vector<int32_t>>
|int[]?
|typing.Optional[typing.List[int]]
|number[] \| null
|[]int32
|
|Array of int32s
|no
|int64[]
|long[]
|optional<std::vector<int64_t>>
|long[]?
|typing.Optional[typing.List[int]]
|Long[] \| null
|[]int64
|
|Array of int64s
|no
|float32[]
|float[] 
|optional<std::vector<float>>
|float[]?
|typing.Optional[typing.List[float]]
|number[] \| null
|[]float32
|
|Array of float32s
|no
|float64[]
|double[] 
|oost::optional<std::vector<double>> 
|double[]?
|typing.Optional[typing.List[float]]
|number[] \| null
|[]float64
|
|Array of float64s
|no
|string[]
|String[] 
|optional<std::vector<optional<std::string>>> 
|string?[]?
|typing.Optional[typing.List[typing.Optional[str]]]
|(string \| null)[] \| null
|[]*string
|
|Array of strings
|no
|decimal[]
|BigDecimal[] 
|optional<std::vector<optional<decimal>>> 
|HBigDecimal?[]?
|typing.Optional[typing.List[typing.Optional[decimal.Decimal]]]
|(BigDecimal \| null)[] \| null
|[]*types.Decimal
|
|Array of Decimals
|no
|time[]
|LocalTime[] 
|optional<std::vector<optional<hazelcast:client:local_time>>> 
|HLocalTime?[]?
|typing.Optional[typing.List[typing.Optional[datetime.time]]]
|(LocalTime \| null)[] \| null
|[]*types.LocalTime
|
|Array of Times
|no
|date[]
|LocalDate[] 
|optional<std::vector<optional<hazelcast:client:local_date>>> 
|HLocalDate?[]?
|typing.Optional[typing.List[typing.Optional[datetime.date]]]
|(LocalDate \| null)[] \| null
|[]*types.LocalDate
|
|Array of Dates
|no
|timestamp[]
|LocalDateTime[] 
|optional<std::vector<optional<hazelcast:client:local_date_time>>> 
|HLocalDateTime?[]?
|typing.Optional[typing.List[typing.Optional[datetime.datetime]]]
|(LocalDateTime \| null)[] \| null
|[]*types.LocalDateTime
|
|Array of Timestamps
|no
|timestampWithTimeZone[]
|OffsetDateTime[] 
|optional<std::vector<optional<hazelcast:client:offset_date_time>>> 
|HOffsetDateTime?[]?
|typing.Optional[typing.List[typing.Optional[datetime.datetime]]]
|(OffsetDateTime \| null)[] \| null
|[]*types.OffsetDateTime
|
|Array of TimestampWithTimeZones
|no
|compact[]
|T[] 
|template<typename T> optional<std::vector<optional<T>>> 
|T?[]?
|typing.Optional[typing.List[typing.Optional[typing.Any]]]
|(T \| null)[] \| null
|[]interface{}
|
|Array of compacts
|no
|nullable-boolean
|Boolean
|optional<bool>
|bool?
|typing.Optional[bool]
|boolean \| null
|*bool
|
|null or 
int8 1 for true
int8 0 for false
|no
|nullable-int8
|Byte
|optional<int8_t>
|sbyte?
|typing.Optional[int]
|number \| null
|*int8
|
|An int8 that can also be null
|no
|nullable-int16
|Short
|optional<int16_t>
|short?
|typing.Optional[int]
|number \| null
|*int16
|
|An iint16 that can also be null
|no
|nullable-int32
|Integer
|optional<int32_t>
|int?
|typing.Optional[int]
|number \| null
|*int32
|
|An int32 that can also be null
|no
|nullable-int64
|Long
|optional<int64_t>
|long?
|typing.Optional[int]
|Long \| null
|*int64
|
|An int64 that can also be null
|no
|nullable-float32
|Float
|optional<float>
|float?
|typing.Optional[float]
|number \| null
|*float32
|
|A float32 that can also be null
|no
|nullable-float64
|Double
|optional<double>
|double?
|typing.Optional[float]
|number \| null
|*float64
|
|A double that can also be null
|no
|nullable-boolean[]
|Boolean[] 
|optional<std::vector<optional<bool>>> 
|bool?[]?
|typing.Optional[typing.List[typing.Optional[bool]]]
|(boolean \| null)[] \| null
|[]*bool
|
|Array of nullable booleans
|no
|nullable-int8[]
|Byte[] 
|optional<std::vector<optional<int8_t>>> 
|sbyte?[]?
|typing.Optional[typing.List[typing.Optional[int]]]
|(number \| null)[] \| null
|[]*int8
|
|Array of nullable int8s
|no
|nullable-int16[]
|Short[] 
|optional<std::vector<optional<int16_t>>>
|short?[]?
|typing.Optional[typing.List[typing.Optional[int]]]
|(number \| null)[] \| null
|[]*int16
|
|Array of nullable i1int6s
|no
|nullable-int32[]
|Integer[] 
|optional<std::vector<optional<int32_t>>>
|int?[]?
|typing.Optional[typing.List[typing.Optional[int]]]
|(number \| null)[] \| null
|[]*int32
|
|Array of nullable int32s
|no
|nullable-int64[]
|Long[] 
|optional<std::vector<optional<int64_t>>> 
|long?[]?
|typing.Optional[typing.List[typing.Optional[int]]]
|(Long \| null)[] \| null
|[]*int64
|
|Array of nullable int64s
|no
|nullable-float32[]
|Float[] 
|optional<std::vector<optional<float>>> 
|float?[]?
|typing.Optional[typing.List[typing.Optional[float]]]
|(number \| null)[] \| null
|[]*float32
|
|Array of nullable float32s
|no
|nullable-float64[]
|Double[] 
|optional<std::vector<optional<double>>> 
|double?[]?
|typing.Optional[typing.List[typing.Optional[float]]]
|(number \| null)[] \| null
|[]*float64
|
|Array of nullable float64
|no
|===


=== Type Ids

Each type supported in the wire format has its type id. The type ids are used while constructing the schemas, performing type checks for user access to fields, and are exposed to the user as a public API.

To distinguish different types supported in the wire-level format, a new enum called `FieldKind` is introduced which has different ids for different types compared to the `FieldType` enum.

The `FieldType` enum has different ways to represent ids for types and their arrays and has some unfortunate public methods which would not fit the new format. (for example `FieldType#DATE` returns `getTypeSize` wrong for the new format). It is desired to have a new enum that does not have those problems and is more open to type additions in the future.

Note that, the new `FieldKind` enum with those new ids will be used in the `GenericRecord` API for both `Portable` and the new format. `FieldType` and `Portable` will be deprecated in the future.

=== Unsigned Integers

There is support for unsigned integer types. The representation of unsigned integers is done with the smallest signed integer type that can represent it (except for `u64`, since there is no such type). So, basically,

* `u8` is represented by → `i16`
* `u16` is represented by → `i32`
* `u32` is represented by → `i64`
* `u64` is represented by → `BigInteger`

=== Enums

There is no support for enums in the wire-level format. The representation of enums is left to the user. 

=== Nullable Primitives

There is support for nullable primitive types as they can be useful in SQL and might play nicely with languages that have a concept to represent them. For example, a C# user might use `Nullable<PrimitiveType>`, or Java users might use the class representation of primitive types.

They are implemented as variable-sized types. The `null` values of such types are represented exactly as `null` variable-sized fields, with the offset of `-1` and no data.

== Header

The partition hash and the type id are common for all serialization methods supported by Hazelcast. Therefore, the new format is no exception and every serialized object has a header in addition to the payload on the wire.

[cols="1,1,1"]
|===
|Name |Type |Description
|Partition hash |i32 |`BIG_ENDIAN` integer, used for key objects. Not applicable to value objects.
|Type id |i32 |`BIG_ENDIAN` integer that determines the serializer to be used. -55 for compact.
|===

== Var-Size Objects

In this section, how a user-defined type is represented at the wire level is described. Consists of `Header`, `Data`, and `Offsets` sections in this order.

=== Header Section

[cols="1,1,1"]
|===
|Name |Type |Description
|Schema id |i64 |	
Hash of the schema.
|Data length |i32 |Length of the DATA SECTION below.
|===

=== Data Section

[cols="1,1"]
|===
|Name |Description
|Fixed-size Fields | Offsets of these fields will be deduced from the schema
|Variable-size Fields | 
|===

=== Offsets Section

[cols="1,1,1"]
|===
|Name |Type |Description
|Variable-Size FieldOffset index 0 |u8/u16/i32 |The index of a field offset is written in the Schema. Offsets of variable length fields. -1 for null
|Variable-Size FieldOffset index 1 |u8/u16/i32 |
|... |... | 
|Variable-Size FieldOffset index n |u8/u16/i32 | 
|===

Note that if the composed data does not include any variable-size field in the schema, `Variable-Size FieldOffset` and `DataLength` will not exist on the wire.

Similarly, if there is no fixed-size field in the schema, `Fixed-Size Fields` will not exist on the wire.

`Variable-Size FieldOffsets` are calculated from the beginning of the `DATA SECTION` shown in the table above.

`Variable-Size FieldOffset` sizes vary depending on the Data Length.

* Data Length <= `254`, offsets are `u8` (`255` is reserved for `null`)
* Data Length <= `65534`, offsets are `u16` (`65535` is reserved for `null`)
* Otherwise, offsets are `i32`.

Length is written before offsets so that the binary can be skipped even when the schema cannot be found.

A Variable-Size FieldOffset is `-1` if a Variable-Size field is `null`.

Fixed-Size Fields cannot be `null`.

== Fixed-Size Fields

The fixed-size fields are written right after the `Length` field consecutively. They are accessed via `offset` written in the Schema.

On the schema, the offset for a fixed-size field is determined as follows:

* The first field always starts from offset 0.
* Fields are ordered by their size in descending order.
* When sizes are the same the fields are ordered by field name.
* Each offset is calculated by adding the size of the last field to the last offset.

The only exception to the above rule is boolean fields. Since up to 8 booleans can be packed into a single byte, they are treated specially, and extra information is stored in the schema (nothing extra on the data) for the bit index of the boolean fields. Boolean fields are written at the end of the fixed-size fields.

== Variable-Size Fields

The offsets of variable-size fields are written at the end in the alphabetical order of the field names. To read a variable-size field from the data, one should read the index of the offset from the Schema. Then read the related index is read from the end of the data to get the offset. The variable-size field can be read from this offset.

On the schema, the index for a variable-size field is determined as follows:

* The fields are given the index incrementally according to the order of the field names starting from 0.

Based on the length of the serialized data, the offsets of the variable-size fields might be represented by 1, 2, or 4 bytes. Note that, this does not mean that offsets will be represented by variable-size integers. It simply means that all variable-size field offsets will either be 1, 2, or 4 bytes per serialized object, depending on its size.

== Schema

[cols="1,1"]
|===
|Name |Type
|type name |string
|number of fields |i32
|name of field 0 |string
|typeid of field 0 |i32
|name of field 1 |string
|typeid of field 1 |i32
|... |...
|name of field n |string
|typeid of field n |i32
|===

When writing a schema to the wire, fields will be ordered according to their name so that the same structure will result in the same byte representation and produce the same schema id.

The offsets and indexes are also decided on the ordered fields. The smaller-sized fields come first. The order is by name within the same size fields.

In the Schema class, each field will either

* have a positive offset, if it is a fixed-size field
* have a positive index if it is a variable-size field
* have a positive bit offset if it is a boolean field. This bit offset is the offset within the byte given by the normal offset

== Schema ID

We are using 64bit https://en.wikipedia.org/wiki/Rabin_fingerprint[Rabin fingerprint] to create [.inline-comment-marker]#a schema id#.

Rabin fingerprint is chosen mostly because it is recommended in Avro’s documents as follows +
https://avro.apache.org/docs/current/spec.html#schema_primitive

[source,text]
----
At the opposite extreme, the smallest fingerprint recommended is a 64-bit Rabin fingerprint. Below, there is a provided pseudo-code for this algorithm that can be easily translated into any programming language. 64-bit fingerprints should guarantee uniqueness for schema caches of up to a million entries (for such a cache, the chance of a collision is 3E-8). It is not recommended to use shorter fingerprints, as the chances of collisions are too high (for example, with 32-bit fingerprints, a cache with as few as 100,000 schemas has a 50% chance of having a collision).
----

The schema id is calculated from the byte array representation of the schema described above.

The implementation that is used is as follows:

[source,java,linenums]
----
long fingerprint64(byte[] buf) {
  if (FP_TABLE == null) initFPTable();
  long fp = EMPTY;
  for (int i = 0; i < buf.length; i++)
    fp = (fp >>> 8) ^ FP_TABLE[(int)(fp ^ buf[i]) & 0xff];
  return fp;
}

static long EMPTY = 0xc15d213aa4d7a795L;
static long[] FP_TABLE = null;

void initFPTable() {
  FP_TABLE = new long[256];
  for (int i = 0; i < 256; i++) {
    long fp = i;
    for (int j = 0; j < 8; j++)
      fp = (fp >>> 1) ^ (EMPTY & -(fp & 1L));
    FP_TABLE[i] = fp;
  }
}
----

== Arrays

Arrays of fix-sized items can not have `null` items. On the other hand, arrays of variable-size items may contain `null` items.

=== Array of Fixed-size Items

[cols=",",options="header",]
|===
|Name |Type
|Number of items |i32
|item 0 |item type
|item 1 |item type
|item 2 |item type
|item n |item type
|===

=== Array of Variable-size Items

Consists of `Header`, `Data`, and `Offsets` sections in this order.

=== Header Section

[cols="1,1"]
|===
|Name |Type
|Data length |i32
|Number of items |i32
|===

=== Data Section

[cols="1,1"]
|===
|Name |Type
|Item 0 | item type
|Item 1 | item type
|... | ...
|Item n | item type
|===

=== Offsets Section

[cols="1,1"]
|===
|Name |Type
|Item 0 offset | u8/u16/i32
|Item 1 offset | u8/u16/i32
|... | ...
|Item n offset | u8/u16/i32
|===


---

An array can contain only a single type of item.
In the case of `Compact[]` all the items must have the same schema, i.e their schema id must be equal. 

Offsets are calculated from the beginning of the `DATA SECTION` shown in the table above.

`Data Length` is the length of the `DATA SECTION` shown in the table above.

Offset sizes vary depending on the Data Length.

* Data Length <= `254`, offsets are `u8` (`255` is reserved for `null`)
* Data Length <= `65534`, offsets are `u16` (`65535` is reserved for `null`)
* Otherwise, offsets are `i32`.

Items can be `null`. The corresponding offset will be set to `-1` in that case.

== Nullable Values

Fixed-size fields will always be on the binary and take up space. On the other hand, when variable-size fields are set to `null`, their offset will be set to `-1` in the binary, and no further data will be written.
