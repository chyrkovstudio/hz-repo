= Persistence Configuration Options
:description: Explore the options for configuring persistence on your members.

{description}

== Global Persistence Configuration

Use the following options to configure the `persistence` object on your members.

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <!-- insert global configuration options here -->
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    # insert global configuration options here
----
--
Java:: 
+ 
--
Add global configuration options to the link:https://docs.hazelcast.org/docs/{full-version}/javadoc/com/hazelcast/config/PersistenceConfig.html[`PersistenceConfig` object].

[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

[cols="1a,1a,1m,2a",options="header"]
|===
|Option|Description|Default|Example



|[[persistence-base-dir]]`base-dir`
|The parent directory in which to store persisted data.

This directory is created automatically if it does not exist.

|persistence
|

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <base-dir>
      /path/to/persistence
    </base-dir>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    base-dir: /path/to/persistence
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setBaseDir(new File("/path/to/persistence"));

config.setPersistenceConfig(PersistenceConfig);
----
--
====


|[[persistence-backup-dir]]`backup-dir`
|The directory in which to store backup snapshots
(hot backups).

a|' ' (empty)

|
See xref:backing-up-persistence.adoc[].

|[[persistence-parallelism]]`parallelism`
|Number of I/O threads that are started concurrently for reading from and writing to files in the persistence store.


Before changing the default, you should measure the raw I/O throughput of your infrastructure and
test with different values of parallelism. In some cases, such as dedicated
hardware, higher parallelism can yield more throughput. In other
cases, such as running on EC2, a higher parallelism can yield diminishing returns with more thread
scheduling, more contention on I/O, and less efficient garbage collection.

|`1`

|
[tabs]
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <parallelism>
      2
    </parallelism>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    parallelism: 2
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setParallelism(2);

config.setPersistenceConfig(PersistenceConfig);
----
--
====


|[[persistence-validation-timeout-seconds]]`validation-timeout-seconds`
|Number of seconds that the cluster allows for members to rejoin and send their partition table to the master member.
|120

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <validation-timeout-seconds>
      120
    </validation-timeout-seconds>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    validation-timeout-seconds: 120
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setValidationTimeoutSeconds(120);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

[[persistence-data-load-timeout-seconds]]
|`data-load-timeout-seconds`
|Number of seconds that the cluster allows for members to finish restoring data from their local persistence store.
|900

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <data-load-timeout-seconds>
      900
    </data-load-timeout-seconds>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    data-load-timeout-seconds: 900
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setDataLoadTimeoutSeconds(900);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

|[[persistence-cluster-data-recovery-policy]]`cluster-data-recovery-policy`
|The data recovery policy that is
respected when the whole cluster restarts.

Valid values are:

* `FULL_RECOVERY_ONLY`: Starts the cluster only when all expected members
are present and correct.
* `PARTIAL_RECOVERY_MOST_RECENT`: Starts the cluster with the members that have most up-to-date partition table and successfully restored their data. All other members leave the cluster and force start themselves. If no members restore their data successfully, the cluster start fails.
* `PARTIAL_RECOVERY_MOST_COMPLETE`: Starts the cluster with the largest group of members that have the same partition table version and successfully restored their data. All other members leave the cluster and force start themselves. If no members restore their data successfully, the cluster start fails.
|FULL_RECOVERY_ONLY

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <cluster-data-recovery-policy>
      FULL_RECOVERY_ONLY
    </cluster-data-recovery-policy>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    cluster-data-recovery-policy: FULL_RECOVERY_ONLY
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setClusterDataRecoveryPolicy(PersistenceClusterDataRecoveryPolicy.FULL_RECOVERY_ONLY);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

[[persistence-auto-remove-stale-data]]
|`auto-remove-stale-data`
|Enables a joining member to automatically remove its persistence store if the cluster's master member considers the persisted data to be stale. See xref:recover-single-member.adoc[].
|true

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <auto-remove-stale-data>
      true
    </auto-remove-stale-data>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    auto-remove-stale-data: true
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setAutoRemoveStaleData(true);

config.setPersistenceConfig(PersistenceConfig);
----
--
====


|[[persistence-encryption-at-rest]]`encryption-at-rest`
|Enables encryption of data in the persistence store.
|disabled
|See xref:encryption-at-rest.adoc[].

|[[persistence-rebalance-delay-seconds]]`rebalance-delay-seconds`
|Number of seconds a cluster waits before repartitioning after a member leaves by means other than a graceful shutdown.
|0
|See xref:recover-single-member.adoc#delaying-migrations[Delaying Migrations].

|===

== Data Structure Persistence Configuration

Use the following options to configure persistence for xref:data-structures:map.adoc[map] and xref:jcache:overview.adoc[JCache] data structures.

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <map name="test-map">
    <data-persistence enabled="true">
      <!-- insert configuration options here -->
    </data-persistence>
  </map>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  map:
  test-map:
    data-persistence:
      enabled: true
      # insert configuration options here
----
--
Java:: 
+ 
--
Add configuration options to the link:https://docs.hazelcast.org/docs/{full-version}/javadoc/com/hazelcast/config/MapConfig.html[`MapConfig` object].

[source,java]
----
Config config = new Config();

MapConfig mapConfig = config.getMapConfig("test-map");
mapConfig.getDataPersistenceConfig().setEnabled(true);

config.addMapConfig(mapConfig);
----
--
====

[cols="1a,1a,1m,2a",options="header"]
|===
|Option|Description|Default|Example


|[[persistence-fsync]]`fsync`
|Guarantees that data is persisted to disk when a write operation returns a successful response to the caller.

By default, data is eventually persisted to disk instead of on every disk write. This generally provides a better performance.
|false

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <map name="test-map">
    <data-persistence enabled="true">
      <fsync>
        false
      </fsync>
    </data-persistence>
  </map>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  map:
  test-map:
    data-persistence:
      enabled: true
      fsync: false
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

MapConfig mapConfig = config.getMapConfig("test-map");
mapConfig.getDataPersistenceConfig().setEnabled(true)
.setFsync(true);

config.addMapConfig(mapConfig);
----
--
====

|`merkle-tree`
|Allows restarting members to synchronize their persisted map or JCache data faster with the rest of the cluster.

|enabled

|See xref:recover-single-member.adoc#synchronizing-data-faster[Synchronizing Data Faster] for more information.
|===

== Job Snapshot Configuration

Use the following option to configure persistence for job snapshots.

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <jet>
    <instance>
      <lossless-restart-enabled>
      true
      </lossless-restart-enabled>
    </instance>
  </jet>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  jet:
    instance:
      lossless-restart-enabled: true
----
--
Java:: 
+ 
--
Use the link:https://docs.hazelcast.org/docs/{full-version}/javadoc/com/hazelcast/jet/config/JetConfig.html[`JetConfig` object].

[source,java]
----
Config config = new Config();
config.getJetConfig().setLosslessRestartEnabled(true);
----
--
====

For lossless restart to work, the cluster must be xref:maintain-cluster:shutdown.adoc#graceful-shutdown[shut down gracefully].
When members are shut down in a rapid succession, Hazelcast triggers
an automatic rebalancing process where backup partitions are promoted
and new backups are created for each member. This may result in
out-of-memory errors or data loss.

Because job data is saved locally on each member, all
members must be present after a restart for Hazelcast to be able to reload
the data.

== Full Example of Persistence Configuration

The following are example configuration settings for a map instance, a JCache instance, and the Jet engine.

[tabs] 
==== 
XML:: 
+ 
-- 
[source,xml]
----
<hazelcast>
    ...
    <persistence enabled="true">
      <base-dir>/mnt/persistence</base-dir>
      <backup-dir>/mnt/hot-backup</backup-dir>
      <validation-timeout-seconds>120</validation-timeout-seconds>
      <data-load-timeout-seconds>900</data-load-timeout-seconds>
      <cluster-data-recovery-policy>FULL_RECOVERY_ONLY</cluster-data-recovery-policy>
      <rebalance-delay-seconds>0</rebalance-delay-seconds>
    </persistence>
    ...
    <map name="test-map">
      <merkle-tree enabled="true" >
        <depth>12</depth>
      </merkle-tree>
      <data-persistence enabled="true">
        <fsync>false</fsync>
      </data-persistence>
    </map>
    ...
    <cache name="test-cache">
      <merkle-tree enabled="true" >
        <depth>12</depth>
      </merkle-tree>
      <data-persistence enabled="true">
          <fsync>false</fsync>
      </data-persistence>
    </cache>
    ...
    <jet>
      <instance>
        <lossless-restart-enabled>true</lossless-restart-enabled>
      </instance>
    </jet>
    ...
</hazelcast>
----
--

YAML::
+
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    base-dir: /mnt/persistence
    backup-dir: /mnt/hot-backup
    validation-timeout-seconds: 120
    data-load-timeout-seconds: 900
    cluster-data-recovery-policy: FULL_RECOVERY_ONLY
    rebalance-delay-seconds: 0
  map:
    test-map:
      merkle-tree:
        enabled: true
        depth: 12
      data-persistence:
        enabled: true
        fsync: false
  cache:
    test-cache:
      merkle-tree:
        enabled: true
        depth: 12
      data-persistence:
        enabled: true
        fsync: false
  jet:
    instance:
      lossless-restart-enabled: true
----
--
Java::
+
--
[source,java]
----
include::ROOT:example$/storage/SampleHotRestartConfiguration.java[tag=hrconf]
----
--
====
